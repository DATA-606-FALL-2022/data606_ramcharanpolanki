{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Exploration"
      ],
      "metadata": {
        "id": "n21xqHfm4fxQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Dt4dgknoWnL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import *\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data"
      ],
      "metadata": {
        "id": "mDfKhj9d8mCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading all the images into a numpy array\n",
        "images = []\n",
        "for file in os.listdir():\n",
        "  if file.endswith('.jpg'):\n",
        "    #if the file is an image\n",
        "    image_values = cv2.imread(file)\n",
        "\n",
        "    #resize the image into 360 x 480 pixels\n",
        "    image_values = cv2.resize(image_values,(360,480))\n",
        "\n",
        "    images.append(image_values)\n",
        "\n",
        "#storing everything in a numpy array\n",
        "images_array = np.array(images)"
      ],
      "metadata": {
        "id": "GDIySlf_4mp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding number of observations"
      ],
      "metadata": {
        "id": "FtWepnOn8n-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_observations = len(images_array)\n",
        "number_of_observations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDxkKLpo8WNG",
        "outputId": "adfbf389-7c3d-4a9a-8e10-42cafd1af897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we are working on a image dataset we do not have any columns "
      ],
      "metadata": {
        "id": "nDGS2zhG8rXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analzing how images are stored in python variables"
      ],
      "metadata": {
        "id": "_grOvEeE60J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_array"
      ],
      "metadata": {
        "id": "ssGbDf8o41_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e019db7-3bee-4ea9-f50a-713197b6a283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 45,  52,  67],\n",
              "         [ 44,  51,  66],\n",
              "         [ 43,  50,  65],\n",
              "         ...,\n",
              "         [ 74,  79,  82],\n",
              "         [ 74,  80,  83],\n",
              "         [ 74,  81,  84]],\n",
              "\n",
              "        [[ 45,  52,  67],\n",
              "         [ 44,  51,  66],\n",
              "         [ 43,  50,  65],\n",
              "         ...,\n",
              "         [ 74,  79,  82],\n",
              "         [ 74,  80,  83],\n",
              "         [ 74,  81,  84]],\n",
              "\n",
              "        [[ 45,  52,  67],\n",
              "         [ 44,  51,  67],\n",
              "         [ 43,  50,  65],\n",
              "         ...,\n",
              "         [ 74,  80,  82],\n",
              "         [ 74,  80,  83],\n",
              "         [ 74,  81,  84]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[236, 225, 227],\n",
              "         [235, 224, 226],\n",
              "         [232, 221, 223],\n",
              "         ...,\n",
              "         [112, 117, 142],\n",
              "         [112, 118, 139],\n",
              "         [112, 119, 138]],\n",
              "\n",
              "        [[236, 225, 227],\n",
              "         [235, 224, 226],\n",
              "         [232, 221, 223],\n",
              "         ...,\n",
              "         [112, 117, 142],\n",
              "         [112, 118, 140],\n",
              "         [112, 119, 139]],\n",
              "\n",
              "        [[236, 225, 227],\n",
              "         [235, 224, 226],\n",
              "         [232, 221, 223],\n",
              "         ...,\n",
              "         [112, 117, 142],\n",
              "         [112, 118, 140],\n",
              "         [112, 119, 139]]],\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [227, 227, 227],\n",
              "         [227, 227, 227],\n",
              "         [227, 227, 227]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [227, 227, 227],\n",
              "         [227, 227, 227],\n",
              "         [227, 227, 227]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [227, 227, 227],\n",
              "         [227, 227, 227],\n",
              "         [227, 227, 227]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[107, 139, 182],\n",
              "         [109, 142, 185],\n",
              "         [113, 147, 190],\n",
              "         ...,\n",
              "         [ 23,  38,  49],\n",
              "         [ 26,  38,  48],\n",
              "         [ 27,  38,  48]],\n",
              "\n",
              "        [[107, 139, 182],\n",
              "         [109, 141, 184],\n",
              "         [114, 147, 190],\n",
              "         ...,\n",
              "         [ 16,  32,  43],\n",
              "         [ 18,  32,  42],\n",
              "         [ 20,  31,  41]],\n",
              "\n",
              "        [[107, 139, 182],\n",
              "         [109, 141, 185],\n",
              "         [114, 147, 190],\n",
              "         ...,\n",
              "         [ 13,  30,  40],\n",
              "         [ 16,  29,  39],\n",
              "         [ 17,  29,  39]]],\n",
              "\n",
              "\n",
              "       [[[ 70,  79, 122],\n",
              "         [ 70,  79, 122],\n",
              "         [ 70,  79, 122],\n",
              "         ...,\n",
              "         [217, 220, 221],\n",
              "         [226, 227, 227],\n",
              "         [230, 230, 230]],\n",
              "\n",
              "        [[ 69,  78, 121],\n",
              "         [ 69,  78, 121],\n",
              "         [ 69,  78, 121],\n",
              "         ...,\n",
              "         [217, 220, 221],\n",
              "         [226, 227, 227],\n",
              "         [230, 230, 230]],\n",
              "\n",
              "        [[ 66,  75, 119],\n",
              "         [ 66,  75, 119],\n",
              "         [ 66,  76, 119],\n",
              "         ...,\n",
              "         [218, 220, 221],\n",
              "         [226, 227, 227],\n",
              "         [230, 230, 230]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 98,  98,  98],\n",
              "         [100, 100, 100],\n",
              "         [106, 106, 106],\n",
              "         ...,\n",
              "         [163, 157, 159],\n",
              "         [163, 157, 159],\n",
              "         [163, 157, 159]],\n",
              "\n",
              "        [[ 98,  98,  98],\n",
              "         [100, 100, 100],\n",
              "         [106, 106, 106],\n",
              "         ...,\n",
              "         [164, 158, 160],\n",
              "         [164, 158, 160],\n",
              "         [164, 158, 160]],\n",
              "\n",
              "        [[ 98,  98,  98],\n",
              "         [100, 100, 100],\n",
              "         [106, 106, 106],\n",
              "         ...,\n",
              "         [164, 159, 160],\n",
              "         [164, 159, 160],\n",
              "         [164, 159, 160]]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = images_array[0].shape\n",
        "shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPKaxQ4_65VN",
        "outputId": "74460d93-61f6-4ae6-862d-36207214d3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480, 360, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_array[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6KOs_RG7SrR",
        "outputId": "91c61d57-08dd-4a34-ee45-58c0bf9b1110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 45,  52,  67],\n",
              "        [ 44,  51,  66],\n",
              "        [ 43,  50,  65],\n",
              "        ...,\n",
              "        [ 74,  79,  82],\n",
              "        [ 74,  80,  83],\n",
              "        [ 74,  81,  84]],\n",
              "\n",
              "       [[ 45,  52,  67],\n",
              "        [ 44,  51,  66],\n",
              "        [ 43,  50,  65],\n",
              "        ...,\n",
              "        [ 74,  79,  82],\n",
              "        [ 74,  80,  83],\n",
              "        [ 74,  81,  84]],\n",
              "\n",
              "       [[ 45,  52,  67],\n",
              "        [ 44,  51,  67],\n",
              "        [ 43,  50,  65],\n",
              "        ...,\n",
              "        [ 74,  80,  82],\n",
              "        [ 74,  80,  83],\n",
              "        [ 74,  81,  84]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[236, 225, 227],\n",
              "        [235, 224, 226],\n",
              "        [232, 221, 223],\n",
              "        ...,\n",
              "        [112, 117, 142],\n",
              "        [112, 118, 139],\n",
              "        [112, 119, 138]],\n",
              "\n",
              "       [[236, 225, 227],\n",
              "        [235, 224, 226],\n",
              "        [232, 221, 223],\n",
              "        ...,\n",
              "        [112, 117, 142],\n",
              "        [112, 118, 140],\n",
              "        [112, 119, 139]],\n",
              "\n",
              "       [[236, 225, 227],\n",
              "        [235, 224, 226],\n",
              "        [232, 221, 223],\n",
              "        ...,\n",
              "        [112, 117, 142],\n",
              "        [112, 118, 140],\n",
              "        [112, 119, 139]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can observe that the images are stored pxiel wise as a 2d matrix where each element in the matrix is an array with 3 values in it. Those three values are RGB values(red green blue) of the pixel "
      ],
      "metadata": {
        "id": "kZunzWj07x6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values"
      ],
      "metadata": {
        "id": "THvNMgjU9JoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the pixel details in the image dataset are used as features for building our dep learning model"
      ],
      "metadata": {
        "id": "ss3_27qG870l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target column: Our model wil be creating new face images by taking inspiration from the images we feed it. We also train a discriminator which identifies whether an image is a real one or generated one"
      ],
      "metadata": {
        "id": "cZYINTxs9Sln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps to be performed in the project**"
      ],
      "metadata": {
        "id": "Gh3nx_fC9ssy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I will be loading the dataset into numpy arrays. \n",
        "* I will preprocess the images like fitting its resolution. \n",
        "* I will be creating a GAN model and training it with the dataset I loaded. \n",
        "* I will be training a discriminator that can filter whether an image is real or generated\n",
        "* Hyper parameter tuning will be performed\n",
        "* I will be creating new images using the generator.\n",
        "* For evaluation purpose, I will be taking a model available on internet to predict if generated image is a human face or not\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7kBr_eho9zLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape):\n",
        "  model = Sequential([                                                      \n",
        "  Conv2D(32, kernel_size=5, strides=2, input_shape=img_shape, padding=\"same\"),                          \n",
        "  LeakyReLU(alpha=0.2),                           \n",
        "  Dropout(0.25),\n",
        "  Conv2D(64, kernel_size=5, strides=2, padding=\"same\"),                          \n",
        "  BatchNormalization(momentum=0.8),                           \n",
        "  LeakyReLU(alpha=0.2),                           \n",
        "  Dropout(0.25),\n",
        "  Conv2D(128, kernel_size=5, strides=2, padding=\"same\"),                         \n",
        "  BatchNormalization(momentum=0.8),                           \n",
        "  LeakyReLU(alpha=0.2),                           \n",
        "  Dropout(0.25),\n",
        "  Flatten(),                            \n",
        "  Dense(1),                           \n",
        "  Activation(\"sigmoid\")\n",
        "  ])\n",
        "                                                    \n",
        "  model.summary()                           \n",
        "  img = Input(shape=img_shape)                           \n",
        "  d_pred = model(img)                           \n",
        "  return Model(inputs=img, outputs=d_pred)"
      ],
      "metadata": {
        "id": "XYUXCv7XyO2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(z_dimension, channels):                           \n",
        "  model = Sequential([\n",
        "  Dense(2 * 120 * 90, input_dim=z_dimension),                           \n",
        "  LeakyReLU(alpha=0.2),                            \n",
        "  Reshape((120, 90, 2)),\n",
        "  UpSampling2D(),                          \n",
        "  Conv2D(128, kernel_size=5, padding=\"same\"),                           \n",
        "  BatchNormalization(momentum=0.8),                           \n",
        "  LeakyReLU(alpha=0.2),\n",
        "  UpSampling2D(),                           \n",
        "  Conv2D(64, kernel_size=5, padding=\"same\"),                           \n",
        "  BatchNormalization(momentum=0.8),                           \n",
        "  LeakyReLU(alpha=0.2),\n",
        "  Conv2D(channels, kernel_size=5, padding=\"same\"),                           \n",
        "  Activation(\"tanh\"),\n",
        "  ])\n",
        "  model.summary()                           \n",
        "  noise = Input(shape=(z_dimension,))                           \n",
        "  img = model(noise)                           \n",
        "  return Model(inputs=noise, outputs=img)"
      ],
      "metadata": {
        "id": "FoIb-ha85BwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load real pictures:                       \n",
        "x_train = images_array                                       \n",
        "# model parameters                       \n",
        "img_rows = shape[0]                       \n",
        "img_cols = shape[1]                       \n",
        "channels = 3                       \n",
        "img_shape = (img_rows, img_cols, channels)                       \n",
        "z_dimension = 32                       \n",
        "optimizer = Adam(0.0005, 0.5)"
      ],
      "metadata": {
        "id": "-4IlLFit7oBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = build_discriminator(img_shape)                       \n",
        "discriminator.compile(loss='binary_crossentropy',                                             \n",
        "                      optimizer=optimizer, metrics=['accuracy'])                                               \n",
        "generator = build_generator(z_dimension,channels)                                               \n",
        "z = Input(shape=(z_dimension,))                       \n",
        "img = generator(z)                       \n",
        "discriminator.trainable = False                       \n",
        "d_pred = discriminator(img)                       \n",
        "combined = Model(z, d_pred)                       \n",
        "combined.compile(loss='binary_crossentropy',optimizer=optimizer,                                        \n",
        "                 metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le-OOCUx8pxX",
        "outputId": "f9d9a178-a5ae-4d0b-b73c-87984ca29e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 240, 180, 32)      2432      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 240, 180, 32)      0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 240, 180, 32)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 120, 90, 64)       51264     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 120, 90, 64)      256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 120, 90, 64)       0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 120, 90, 64)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 45, 128)       204928    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 60, 45, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 60, 45, 128)       0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 60, 45, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 345600)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 345601    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 604,993\n",
            "Trainable params: 604,609\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 21600)             712800    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 21600)             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 120, 90, 2)        0         \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 240, 180, 2)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 240, 180, 128)     6528      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 240, 180, 128)    512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 240, 180, 128)     0         \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, 480, 360, 128)    0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 480, 360, 64)      204864    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 480, 360, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 480, 360, 64)      0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 480, 360, 3)       4803      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 480, 360, 3)       0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 929,763\n",
            "Trainable params: 929,379\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 30000\n",
        "batch = 64\n",
        "\n",
        "real_imgs = np.ones((batch, 1))\n",
        "fake_imgs = np.zeros((batch, 1))\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    index = np.random.randint(0, x_train.shape[0], batch)\n",
        "    images = x_train[index]\n",
        "    sample_noise = np.random.normal(0, 1, (batch, z_dimension))\n",
        "    gen_images = generator.predict(sample_noise)\n",
        "\n",
        "    fake_imgs_discriminator_loss = discriminator.train_on_batch(gen_images, fake_imgs)\n",
        "    real_imgs_discriminator_loss = discriminator.train_on_batch(images, real_imgs)\n",
        "    \n",
        "    total_discriminator_loss = np.add(real_imgs_discriminator_loss, fake_imgs_discriminator_loss)/2\n",
        "    sample_noise = np.random.normal(0, 1, (batch, z_dimension))\n",
        "    g_loss = combined.train_on_batch(sample_noise, real_imgs)\n",
        "    \n",
        "generator.save(\"generator.h5\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO7ZBeD09JwS",
        "outputId": "64c3c26f-39c8-4bbc-eda0-8f81e367cbc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 73s 36s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vh3Yc19oa-vn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}